{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MasterMatthew\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['resize']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "#Autoreload so changing py files works\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from Util import *\n",
    "from superpoint import *\n",
    "from VideoStabilization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SUPERFeatureExtractor(BaseFeatureExtractor):\n",
    "    def __init__(self):\n",
    "        self.superpt = SuperPointFrontend(weights_path='./superpoint_v1.pth',\n",
    "                      nms_dist=4,\n",
    "                      conf_thresh=0.05,\n",
    "                      nn_thresh=0.7,\n",
    "                      cuda=False)\n",
    "    \n",
    "    def extractFeatures(self, image):\n",
    "        return self.superpt.run(image)\n",
    "def match(desc1, desc2):\n",
    "    pTracker = PointTracker(2,0.7)\n",
    "    return pTracker.nn_match_two_way(desc1, desc2, 0.4)\n",
    "def convertToPoints(pts1, pts2, matches):\n",
    "    pointsx1 = pts1[0]\n",
    "    pointsy1 = pts1[1]\n",
    "    pointsx2 = pts2[0]\n",
    "    pointsy2 = pts2[1]\n",
    "    pts1_pair = []\n",
    "    pts2_pair = []\n",
    "    #print(len(pointsx1))\n",
    "    #print(len(pointsx2))\n",
    "    #print(np.max(matches[0]))\n",
    "    #print(np.max(matches[1]))\n",
    "    for i in range(matches.shape[1]):\n",
    "        queryIdx=int(matches[1][i])\n",
    "        trainIdx=int(matches[0][i])\n",
    "\n",
    "        size_1 = len(pointsx1)-1\n",
    "        size_2 = len(pointsx2)-1\n",
    "\n",
    "        if queryIdx>size_1 or trainIdx>size_2:\n",
    "            continue\n",
    "\n",
    "        pt1 = (int(pointsx1[queryIdx]), int(pointsy1[queryIdx]))\n",
    "        pt2 = (int(pointsx2[trainIdx]), int(pointsy2[trainIdx]))\n",
    "        pts1_pair.append(pt1)\n",
    "        pts2_pair.append(pt2)\n",
    "    return np.array(pts1_pair), np.array(pts2_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath = 0\n",
    "resize = (800, 600)\n",
    "skip = 0\n",
    "max_frames = 9999\n",
    "show = True\n",
    "\n",
    "SUPERPOINT=False\n",
    "if SUPERPOINT:\n",
    "    extractor = SUPERFeatureExtractor()\n",
    "else:\n",
    "    extractor = SIFTFeatureExtractor()\n",
    "    matcher = BFMatcherHomographyGenerator()\n",
    "\n",
    "def read():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[0] < frame.shape[1]:\n",
    "        frame = cv2.transpose(frame)\n",
    "        frame = cv2.flip(frame, 1)\n",
    "    if resize:\n",
    "        frame = cv2.resize(frame, resize)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    color = frame#cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    return color, gray\n",
    "\n",
    "cap = cv2.VideoCapture(inputpath)\n",
    "correctedFrames = []\n",
    "count = 0\n",
    "H = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "\n",
    "#Read first frame\n",
    "color1, gray1 = read()\n",
    "correctedFrames.append(color1)\n",
    "kps1, desc1 = extractor.extractFeatures(gray1)\n",
    "\n",
    "while cap.isOpened():\n",
    "    #Read in next frame\n",
    "    color2, gray2 = read()\n",
    "    count = count + 1\n",
    "    #Allow frame skipping\n",
    "    if count > max_frames: break\n",
    "    if count % skip == 0:\n",
    "        kps2, desc2 = extractor.extractFeatures(gray2)\n",
    "        if SUPERPOINT:\n",
    "            matches = match(desc1, desc2)\n",
    "            pair1, pair2 = convertToPoints(kps1, kps2, matches)\n",
    "            HG, mask = cv2.findHomography(pair2, pair1, cv2.RANSAC, 5.0)\n",
    "        else:\n",
    "            HG = matcher.findHomography(kps2, desc2, kps1, desc1)\n",
    "        H = H @ HG\n",
    "        corrected = cv2.warpPerspective(color2, H, (color2.shape[1], color2.shape[0]))\n",
    "        correctedFrames.append(corrected)\n",
    "        kps1 = kps2\n",
    "        desc1 = desc2\n",
    "        \n",
    "        if show:\n",
    "            cv2.imshow('frame', corrected)\n",
    "    #Press space to end\n",
    "    if cv2.waitKey(32) == 32:\n",
    "        break\n",
    "    \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
